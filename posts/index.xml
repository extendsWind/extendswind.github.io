<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on extendswind</title>
    <link>https://extendswind.top/posts/</link>
    <description>Recent content in Posts on extendswind</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 29 May 2019 20:30:00 +0800</lastBuildDate>
    
	<atom:link href="https://extendswind.top/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>log4j 1.2 配置和使用简述</title>
      <link>https://extendswind.top/posts/technical/log4j_properties_simple_introduction/</link>
      <pubDate>Wed, 29 May 2019 20:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/log4j_properties_simple_introduction/</guid>
      <description>简述 使用log4j可以根据配置文件控制输出日志的级别，记录到文件、命令行等的位置，不需要代码上的更改。
日志在一定程度上会影响性能，特别是高并发环境。一般更建议使用log4j 2.x，在性能上有较大的提高，由于hadoop 2.7使用的log4j 1.2，下面主要写这一版本。
 根据日志级别记录日志 (logger上设置） 运行时决定具体的记录位置（appender上设置）和日志格式（layout上设置）  一些概念 日志级别（priority，代码里为level） 日志级别从低到高为trace, debug, info, warn, error, fatal。默认级别为info，低于设置级别的日志不会被打印。
常用组件 一般情况下常设置的组件有logger，appender， layout。
用类的方式表达三个组件的关系为
Logger{ name; level; // 控制日志级别 appenderList; // 可对应多个appender } Appender{ name; // 控制文件位置 如fileAppender layout; // 控制格式 filter; // 过滤部分日志 }  logger logger以一种树状关系管理日志的类型，log4j.rootCategory为根节点，如果没有标记 log4j.additivity.MyLogger = false ，则子logger会默认继承上一级的设置。
通过树的组织形式，对不同的包中的不同的类，可以分别设置不同的日志方式。
通过点表示层级，如com.foo为com.foo.Bar的上级
关于category，早期的log4j使用category较多，但在log4j 1.2之后，建议使用logger代替category。
appender 主要用于
 控制日志的输出位置，当前支持the console, files, GUI components, remote socket servers, NT Event Loggers, and remote UNIX Syslog daemons.</description>
    </item>
    
    <item>
      <title>阅读《人类简史》-- 1.认知革命</title>
      <link>https://extendswind.top/posts/life/reading_brief_history_of_humankind_1/</link>
      <pubDate>Tue, 02 Apr 2019 11:25:25 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/life/reading_brief_history_of_humankind_1/</guid>
      <description>人类相比一般动物在身体上的特殊性 大脑和直立行走。
脑容量的增大使人类拥有更强的思维能力；直立行走使人类的手能做更多一般动物做不了的事，如制作和使用工具，尤其是使用火。但脑容量的增加导致耗能增加，只占体重的2%却消耗20%的能量，其它猿类只占约8%，直接导致了肌肉萎缩。
直立行走使臀部变窄，使女性为了正常生育只能让婴儿提前出生，导致人类婴儿早期发育时间相比其它动物较长。同时，由于一个人很难照顾下一代间接促进了人类的合作。
人类使用的石器工具更多的是用来敲碎骨头吃其它动物剩下的骨髓，此时还只是在食物链中层。用火使人类相比其它动物能够动用超越自身身体的力量，初步战胜其它的动物。并且用火烹饪过的食物病菌和寄生虫更少且易于消化。
语言能力的发展与认知革命 在非洲的智人走向世界前，人类还有欧洲的尼安德特人和亚洲的直立人等，同样掌握了用火和使用工具等技术以及群体协作。大约7万年前，智人从非洲向其它区域扩张，智人所到之处的其它人类开始在地球上消失，最终智人统治整个地球。对于智人为什么能够战胜其它的人类，书中给了一个很有意思的观点，最重要的靠的是智人在语言交流上的虚构能力（认知革命）。
通过很多动物都存在的简单语言，使人类能够进行小规模的合作（如传达危险信息等）。而相比动物表达的“小心，有危险”，人类能够更精确的表达出“在附近xx方向距离xx的位置有xx只狮子，我们应该&amp;hellip;”。
书中认为人类的语言交流更重要的是了解人类之间的信息以创建一个巨大的团队，如一个部落的其它人员做什么、谁更靠谱。作者提到现代智人能够聊天长达数小时之久，通过日常聊天交流，使人类能够更容易了解群体的信息。但根据其它动物以及现代人类的观察，仅仅凭借一般的语言交流难以维持一个更大规模的群体（难以超过150人），黑猩猩族群极少情况下能超过100只，数量增加容易造成族群分裂，现代的公司人数超过150人必须使用更强的管理模式。
作者认为智人能够维护更大部落的能力，来自于能够构建并且相信虚构的事物（认知革命），如宗教、神话、国家甚至是现在的国家体系。可能一句神的指示就能调动成千上万的智人团结起来做一件事，而智人以外从地球上消失的其它原始人类很可能不具备这一能力。智人通过认知革命解决了一般哺乳类动物很难组成较大群体的问题，虚构能力使人类能以类似国家的形式维持大规模的群体。
绕过基因组的快速进化 人类使用工具和大规模协作已经在食物链中的地位不断上升，通过语言交流和文字等形式又进一步加速了进化，开启了一条采用“文化演化”的快速道路。过去想要改变社会结构、发明新科技或是移居到新的地点，多半是因为基因突变、环境压力，需要一个相当漫长的过程。而人类能力的发展不再仅仅依赖基因上的改变，知识能够在一代又一代的发展中大量积累而不是重新开始。
智人走向全世界的过程中导致了大量物种的灭绝，主要证据来源于很多大型动物的灭绝时间和智人抵达的时间吻合。传统的进化方式使物种之间有一个漫长的适应期，狮子捕猎能力加强的同时其它猎物也在不断的提高躲避能力。就像现代人开着坦克飞机穿越到古代，人类的“文化演化”道路直接打破了生态的平衡。
个人理解 这本书的后几个章节也经常提到虚构。比如人权、自由、道德约束等，在最初的自然界并不存在，对于地球上的生存法则也不一定理所当然，但却成了如今人类社会大多数人所接受的东西。不断的进行各种虚构，并通过战争等一系列的生存竞争不断的检验和提高虚构的程度，有点定向基因突变的感觉。
很多虚构不一定科学但有意想不到的结果。原始社会里神的存在，或许最初只是因为某些难以解释的自然现象，却很有可能是智人统治全球的原因之一。只因为大多数人相信规则。
很多虚构也不一定都在往更好的方向发展。战争与竞争促进了社会生产力的不断提高，但并没有带来幸福度的大幅提升，当前社会带来的各种压力和欲望很多也出自于虚构，少有人能选择打破或逃避。也只因为大多数人相信规则。
一个虚构的规则，一旦被大多数人相信而且短期无法被撬动，就会像一个真实具体的事物。或许相信规则也算是人类进化出的能力之一。社会一直都是少部分人改变规则而大多数人遵守。
通过不断的创造故事与相信故事，人类已经编织出一个复杂的故事网络，制定出一系列超越自然界本身的规则。现代社会仍旧在制定各种规则。也在挑战各种规则。</description>
    </item>
    
    <item>
      <title>anki的使用以及anki server的配置</title>
      <link>https://extendswind.top/posts/technical/anki_and_anki_server/</link>
      <pubDate>Mon, 04 Mar 2019 21:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/anki_and_anki_server/</guid>
      <description>首先吐槽，anki作为老牌软件，国内资料并不多。
虽然html的卡片显示和python的插件式开发上看比较适合程序员，但从各种配置上感觉程序员用户量并不大。
因此，想深度使用准备折腾。
简单使用  淘制作好的卡片，导入 卡片可以套模板更美观（添加时的Cards选项，支持html） 插件里的awesome TTS很多人推荐但速度略慢 添加单词可以用Word Query  官方文档https://apps.ankiweb.net/docs/manual.html
插件编写文档https://apps.ankiweb.net/docs/addons.html
一些坑 删除卡片不会删除对应的媒体文件，需要点击 check media 后手动删除。
anki server 的安装 官网的速度爆表，而且有数据安全问题，因此官网给出了自建anki server的解决方案。
百度上的大多使用 https://github.com/dsnopek/anki-sync-server ，可以基于pip2和python2直接安装，个人在基于Arch的linux下感觉坑多，在linux上的anki 2.1.9连不上上面python2的服务器（bug解决一个又出一个），更建议使用基于python3的fork项目：https://github.com/tsudoko/anki-sync-server 。
基于python3的仓库 github上的readme已经写得比较清楚，下面的搬运点大概。
1、clone 仓库
git clone https://github.com/tsudoko/anki-sync-server.git
2、安装anki或anki-bundled相关的库
直接使用包管理器安装 sudo pacman -S anki
如果包管理器里没有anki（如debian），也可以用pip安装anki-bundled相关的库
$ git submodule update --init # anki-bundled已经加入为submodule，可以先更新 $ cd anki-bundled $ pip install -r requirements.txt # 安装相关的库 3、安装webob
pip install webob
4、修改 ankisyncd.conf 文件
文件中保存了主要的配置，主要改端口，默认端口一般也就能用。
5、创建用户</description>
    </item>
    
    <item>
      <title>linux 关闭主板上的蜂鸣器声音</title>
      <link>https://extendswind.top/posts/technical/mainboard_speaker_close/</link>
      <pubDate>Fri, 25 Jan 2019 10:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/mainboard_speaker_close/</guid>
      <description>在从deepin的kdd桌面换到xfce桌面后，命令行和界面操作上动不动会让主机响一声。
manjaro的xfce版也是如此，不知道是不是linux下xfce的通病。
主要是搜索的时候百度的结果很奇葩&amp;hellip;
用关键字 beep of xfce4 搜到了arch wiki下的内容，原来这玩意叫pc speaker，针对不同的情况有不同的解决方案。
最简单粗暴的方式 内核中加载了pcspkr模块导致的主板声音，rmmod移除此模块，然后/etc/modprobe.d文件夹下加入黑名单，使开机过程不加载。
 rmmod pcspkr echo &amp;ldquo;blacklist pcspkr&amp;rdquo; &amp;gt; /etc/modprobe.d/nobeep.conf  具体参考 https://wiki.archlinux.org/index.php/PC_speaker</description>
    </item>
    
    <item>
      <title>manjaro AwesomeWM 上使用双显示器</title>
      <link>https://extendswind.top/posts/technical/dual_monitor_manjaro_awesome/</link>
      <pubDate>Thu, 24 Jan 2019 21:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/dual_monitor_manjaro_awesome/</guid>
      <description>安装manjaro时使用独显的单显示器，在主板上接第二个显示器一直没反应。
几个问题和解决 BIOS里检查是否关闭了集显开关 大多数显卡的默认设置都会在识别独显后关闭集显，要使用集显上的接口需要单独设置。
如果接口允许，最好将两个显示器都接在独显上。
基于KDE等桌面 如果主板和显卡驱动正常，一般各大桌面环境都支持GUI配置，可以在显示设置里直接修改。
使用 xrandr 识别和控制显示器 xrandr 直接执行会得到显示器的连接状态，获取显示器的名称后可以用下面的命令显示。
（其中DVI-I-1-1与VGA1为两个显示器的名称）
xrandr --output DVI-I-1-1 --mode 1440x900 --primary --output VGA1 --mode 1366x768 --pos 1440x132 设置输出的显示器以及显示参数，每个--output后接显示器名以及参数，--mode指定分辨率，--primary指定主显示器，--pos指定位置，或者用--right-of指定相对位置。
更进一步的设置可以在arch wiki
xrandr 找不到显示器 xrandr &amp;ndash;listproviders 得到当前的显示器输入设备（一般name为Intel的是集显，name为nouveau的是开源独显驱动，Nvidia为闭源显卡驱动）
xrandr &amp;ndash;setprovideroutputsource 0 1 将上面的设备设置为输入源
如果xrandr &amp;ndash;listproviders 没有得到所有的输入源，则需要折腾驱动。
驱动问题 一般建议将两个显示器都接在独显上，出问题的概率更低（独显一般口不够或者需要转换略尴尬）。
我将显示器分别接在独显和主板接口上，在manjaro和deepin两个系统下都发现NVIDIA驱动有问题，primary显示器会显示两个显示器的内容。而将显卡驱动切换到开源驱动（nouveau）时正常(据说开源驱动性能略低）。
mhwd -li --pci 查看已经安装的驱动 mhwd -l --pci 查看能用的驱动 sudo mhwd -r pci video-nvidia 移除驱动video-nvidia sudo mhwd -a pci videa-linux 安装开源显卡驱动（nouveau）  manjaro上通过mhwd简化了各种配置，详见：
https://wiki.manjaro.org/index.php/Configure_Graphics_Cards
AwesomeWM 默认快捷键：</description>
    </item>
    
    <item>
      <title>manjaro (arch) 安装搜狗输入法</title>
      <link>https://extendswind.top/posts/technical/sogou_input_install_in_arch_manjaro/</link>
      <pubDate>Mon, 21 Jan 2019 20:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/sogou_input_install_in_arch_manjaro/</guid>
      <description>本来还很简单的事，被默认的选项弄出一堆坑
步骤 先安装fcitx用来管理输入法，然后安装搜狗输入法并配置，然后添加环境变量使相关的应用默认加载fcitx。
1. 安装fcitx以及配置 sudo pacman -S fcitx fcitx-im fcitx-configtool
fcitx 为基础安装包，fcitx-im用于GTK/QT等界面上使用的包，fcitx-configtool为配置界面（kde下还能安装一个kde版的configtool）。
2. 安装搜狗输入法 yaourt fcitx-sogoupinyin
此处有坑，默认的安装方式会编译安装qtwebkit，速度非常的慢（一个小时午觉后还没好&amp;hellip;)
在库的官方说明中（来自 https://aur.archlinux.org/packages/fcitx-sogoupinyin/ ）依赖项为qtwebkit (qtwebkit-bin)
其实只依赖qtwebkit-bin，因此先安装qtwebkit-bin可以解决依赖问题（不到一分钟&amp;hellip;)
yaourt -S qtwebkit-bin
3. fcitx 设置中添加搜狗拼音 fcitx configuration中点加号添加sogou pinyin（默认语言为英语时需要勾选一个选项）
4. fcitx环境变量的添加 gui应用的环境变量一般不通过profile和bashrc。
arch wiki下的内容：
 KDM, GDM, LightDM 等显示管理器，请使用 ~/.xprofile arch wiki 警告: 上述用户不要在~/.xinitrc中加入下述脚本，否则会造成无法登陆。(但在里头加了也没挂) 如果您用 startx 或者 Slim 启动，请使用~/.xinitrc 中加入
export GTK_IM_MODULE=fcitx export QT_IM_MODULE=fcitx export XMODIFIERS=@im=fcitx
如果你使用的是较新版本的GNOME，使用 Wayland 显示管理器，则请在/etc/environment中加入
GTK_IM_MODULE=fcitx QT_IM_MODULE=fcitx XMODIFIERS=@im=fcitx
 参考链接中有更详细的说明，我用的manjaro+xfce4以及后面改装的cinnamon和awesome都是在lightDM下该的.xinitrc，没有.xprofile文件，也能正常用。 （注意添加在最后exec $(&amp;hellip;)的前面）</description>
    </item>
    
    <item>
      <title>arch linux (manjaro) 下运行tim和qq</title>
      <link>https://extendswind.top/posts/technical/tim_install_wine/</link>
      <pubDate>Sun, 20 Jan 2019 21:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/tim_install_wine/</guid>
      <description>基于AUR的安装是没什么难度了，主要安装后会出各种问题，还有选不同的包的影响。
官方的wiki上推荐安装deepin-wine-tim，基于wine和最新版的tim。安装后存在qq密码每次都要输入的问题（201804测试没有此问题，但还是不太稳定，2018年因为wine的更新导致挂了两次只能回退）。
更推荐使用的deepin.com.qq.office，基于deepin-wine，配置好了比较稳定。
安装步骤 安装 yaourt -S deepin.com.qq.office
ps：吐槽，安装deepin-wine的各个确认略多。 d
qq提取消息、截图等快捷键设置 在/opt/deepinwine/tools/sendkeys.sh脚本能够传递快捷键，如直接运行./sendkeys.sh a 则会向qq或tim进程发送 ctrl+alt+a。
不同桌面环境添加快捷键的方法差不多，主要步骤：
 setting -&amp;gt; keyboard -&amp;gt; shortcut 添加快捷键，选择上面的脚本，在脚本后面加上a 指定运行脚本的快捷键  此时按快捷键后相当于qq中按 ctrl+alt+a (截图)
同理可以设置qq其它快捷键
一般问题 大多出现在基于wine的tim上，基于deepin的tim问题很少。
deepin-wine在非gnome系的桌面上的运行问题 3wm, kde, awesome等桌面管理器或桌面环境里运行基于deepin-wine的qq和tim时，会出现下面的错误
 X Error of failed request: BadWindow (invalid Window parameter) Major opcode of failed request: 20 (X_GetProperty)
 由于deepin-wine依赖了gnome系（mate,cinnamon,gnome）的setting-daemon，需要安装后运行（一般加入开机启动）
sudo pacman -S cinnamon-settings-daemon /usr/lib/cinnamon-settings-daemon/csd-xsettings 无法输入中文 如果其它地方可以使用输入法，一般为环境变量的问题，fcitx没有配置好。
粗暴解决方式: 下面的文件夹中加入环境变量
/opt/deepinwine/apps/Deepin-TIM/run.sh
 export XMODIFIERS=&amp;ldquo;@im=fcitx&amp;rdquo; export GTK_IM_MODULE=&amp;ldquo;fcitx&amp;rdquo; export QT_IM_MODULE=&amp;ldquo;fcitx&amp;rdquo;</description>
    </item>
    
    <item>
      <title>在非gnome系桌面环境下运行deepin-wine tim的错误解决</title>
      <link>https://extendswind.top/posts/technical/deepin_wine_run_in_not_gnome_desktop_environment/</link>
      <pubDate>Sun, 20 Jan 2019 20:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/deepin_wine_run_in_not_gnome_desktop_environment/</guid>
      <description>i3wm, kde, awesome等桌面管理器或桌面环境里运行基于deepin-wine的qq和tim时，会出现下面的错误
 X Error of failed request: BadWindow (invalid Window parameter) Major opcode of failed request: 20 (X_GetProperty)
 在gnome、mate、cinnamon三个桌面上运行较好，xfce4上运行有少许焦点上的bug，其它桌面环境和管理器下直接出上面的错误。
最近终于在aur上看到是因为deepin-wine依赖了gnome-settings-daemon（gnome系的cinnamon和mate的对应组件也能用），启动后就能正常运行，但AwesomeWM会使用xsettings对应的主题，KDE基本正常运行，其它非gnome系的桌面环境未测试。
解决方案 1. 安装gnome-settings-daemon (arch 系） sudo pacman -S gnome-settings-daemon ubuntu 下的包和运行的程序名略不一样，参考：
https://github.com/wszqkzqk/deepin-wine-ubuntu/issues/12#issuecomment-443656358
2. 在tim启动脚本中加入启动 /opt/deepinwine/apps/Deepin-TIM/run.sh 的文件前添加下面的行：
/usr/lib/gsd-xsettings &amp;amp;
注意 主要缺点——影响主题（某些桌面环境） AwesomeWM在使用xsettings之后，主题等需要与对应的xsettings设置相对应。如使用gnome-settings-daemon时，需要在gnome的设置里更改主题。使用lxappearance修改主题只会更改~/.gtkrc-2.0等文件，不会生效。
csd-xsettings 的影响 因为大小和简洁的原因从gnome的xsettings换到了cinnamon的xsettings，下面的设置在gsd-xsettings上未测试。
csd-xsettings 主要影响两个地方：1. 启动过程； 2. 在tim内调用外部程序打开链接的过程（如打开网页、打开本地目录）。
可以考虑启动后关闭对tim，可以避免影响系统主题一类的问题，但会导致无法调用外部程序。加上运行后5s关闭的参数即可:
/usr/lib/cinnamon-settings-daemon/csd-xsettings --exit-time 5 &amp;amp;
附：使用cinnamon的xsettings的设置 主题的问题在awesome这种环境下略坑，懒得去试gnome上的主题设置需要哪些包，安装整个gnome的包需要800多M，直接安装了cinnamon的基础包（90M左右）。和gnome只是些名字上的区别：
sudo pacman -S cinnamon # awesome的autorun里加入下面程序使开机运行 /usr/lib/cinnamon-settings-daemon/csd-xsettings 在系统设置里可以下载和更改主题
小坑  tim和qq会在点击好友图像时卡死的情况。原因之一可能是pulseaudio进程，kill掉就行，会影响声音的调整。（千里之外的两个程序不知道为什么会卡一起）</description>
    </item>
    
    <item>
      <title>zotero zotfile插件 pdf附件文件夹在多系统下的同步设置</title>
      <link>https://extendswind.top/posts/research/zotero_multiple_directory_pdf_sync/</link>
      <pubDate>Wed, 09 Jan 2019 09:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/research/zotero_multiple_directory_pdf_sync/</guid>
      <description>之前的附件使用zotfile单独的文件夹管理，换了一块硬盘，挂载目录发生变化后zotero里所有的附件都打不开，在zotero的目录设置和zotfile的目录设置里改了都没用。
使用sqllite的浏览器看了一眼zotero的存储数据库(zotero.sqlite)，在表itemAttachments中存储了所有附件的类型地址等信息，发现里头的地址全都使用的绝对路径！！
重点在于设置zotero和zotfile的附件路径和转移文件。
使用网盘同步的不用折腾这些。
方法一：设置为相对路径并修改文件 设置  zotero preferences -&amp;gt; Files and Folders -&amp;gt; Linked Attachment Base Directory 设置存储路径 （注意不是 data directory） 把zotfile里的路径也改到这（不知道具体什么机制，zotfile有个相对路径的pull request不知道读的是不是这个，懒得多折腾）  已有的文件移动  如果由于换硬盘换系统一类的问题，先使用软连接指向原来的目录，让zotero能够找到原来的文件。（源目录可以使用sqllite的浏览器看到）
 在library下全选所有的items，然后右键 Manage Attachments -&amp;gt; Rename Attachments。（看起来是重命名，实质上会移动所有的文件）
  此时此前附件中的绝对路径/mnt/data/...会变成attachments：catagory1/test1.pdf 类似的相对路径。
方法二：直接操作sqllite数据库来改 下面的语句供参考，建议稍了解后操作，使用update导致数据丢失会很麻烦。
把下面路径中的/home/fly/public_download/改成自己数据库里的路径即可。
update itemAttachments set path=replace(path, &#39;/home/fly/public_download/&#39;, &#39;attachments:&#39;) where path like &#39;/home/fly/public_download%&#39;  最后 跨操作系统或者跨目录直接设置到相同的目录即可。</description>
    </item>
    
    <item>
      <title>Spark设置自定义的InputFormat读取HDFS文件</title>
      <link>https://extendswind.top/posts/technical/problem_spark_reading_hdfs_serializable/</link>
      <pubDate>Sat, 15 Dec 2018 11:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/problem_spark_reading_hdfs_serializable/</guid>
      <description>Spark提供了HDFS上一般的文件文件读取接口 sc.textFile()，但在某些情况下HDFS中需要存储自定义格式的文件，需要更加灵活的读取方式。
使用KeyValueTextInputFormat Hadoop的MapReduce框架下提供了一些InputFormat的实现，其中MapReduce2的接口(org.apache.hadoop.mapreduce下)与先前MapReduce1(org.apache.hadoop.mapred下)有区别，对应于newAPIHadoopFile函数。
使用KeyValueTextInputFormat的文件读取如下
import org.apache.hadoop.mapreduce.lib.input.KeyValueTextInputFormat import org.apache.hadoop.io.Text val hFile = sc.newAPIHadoopFile(&amp;#34;hdfs://hadoopmaster:9000/user/sparkl/README.md&amp;#34;, classOf[KeyValueTextInputFormat], classOf[Text], classOf[Text]) hFile.collect 使用自定义InputFormat InputFormat是MapReduce框架下将输入的文件解析成字符串的组件，Spark对HDFS中的文件实现自定义读写需要通过InputFormat的子类实现。下面只写简单的思路，具体的可以参考InputFormat和MapReduce相关资料。
InputFormat的修改可以参考TextInputFormat，继承FileInputFormat后，重载createRecordReader返回一个新的继承RecordReader的类，通过新的RecordReader读取数据返回键值对。
打包后注意上传时将jar包一起上传：
`./spark-shell &amp;ndash;jars newInputFormat.jar
运行的代码和上面差不多，import相关的包后
val hFile = sc.newAPIHadoopFile(&amp;#34;hdfs://hadoopmaster:9000/user/sparkl/README.md&amp;#34;, classOf[NewTextInputFormat], classOf[Text], classOf[Text]) 一些坑 序列化问题 在读取文件后使用first或者collect时，出现下面的错误
 ERROR scheduler.TaskSetManager: Task 0.0 in stage 2.0 (TID 18) had a not serializable result: org.apache.hadoop.io.IntWritable Serialization stack: - object not serializable (class: org.apache.hadoop.io.IntWritable, value: 35) - element of array (index: 0) - array (class [Lorg.</description>
    </item>
    
    <item>
      <title>Hadoop 机架（集群拓扑）设置</title>
      <link>https://extendswind.top/posts/technical/hadoop_rack_awareness/</link>
      <pubDate>Wed, 12 Dec 2018 11:20:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/hadoop_rack_awareness/</guid>
      <description>Hadoop会通过集群的拓扑（节点在交换机的连接形式）优化文件的存储，降低跨交换机的数据通信，使副本跨交换机以保证数据安全。
但Hadoop没有默认的集群拓扑识别机制，需要使用额外的java类或脚本两种形式设置。
官网上给了集群拓扑的基本说明（!(Rack Awareness)[https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/RackAwareness.html]），给出来的那两段脚本看得有点懵，就自己试了一下，写了个更简单的。
其实只是Hadoop会调用脚本，将多个Datanode的ip作为输入，每次最多输入的ip数设置在net.topology.script.number.args，将输入的ip转换成/rack-num的形式(以/开头的字符串)，用标准输出流（如Python的print）输出结果。
具体操作 编写脚本 下面的脚本在输入
192.168.3.1 192.168.3.4  时，会输出
/rack1 /rack4  #!/bin/python3 import sys # 第一个参数是脚本路径，直接pop掉 sys.argv.pop(0) # 0-3 rack0 # 4-7 rack1 # 8-11 rack2 # ... # 其它的参数里每个参数都是一个ip，此处直接取ip的最后一位除以4作为Racknum # 实践上可以读文件确定ip的对应关系 for ip in sys.argv: hostNum = int(ip.split(&amp;#34;.&amp;#34;)[3]) print(&amp;#34;/rack&amp;#34; + str(int(hostNum/4))) 设置配置参数 &amp;lt;property&amp;gt; &amp;lt;name&amp;gt;net.topology.script.file.name&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;/home/sparkl/hadoop/etc/hadoop/topology.py&amp;lt;/value&amp;gt; &amp;lt;/property&amp;gt; 重启集群即可
验证结果 以下命令能够直接获取某一个文件的分布状态，以及总的rack数量：
hdfs fsck /readme.md -files -blocks -racks
貌似没有直接以树状的形式输出集群拓扑的命令，namenode的日志中能看到datanode在连接时的拓扑位置。</description>
    </item>
    
    <item>
      <title>Hadoop 副本放置策略的源码阅读和设置</title>
      <link>https://extendswind.top/posts/technical/hadoop_block_placement_policy/</link>
      <pubDate>Tue, 11 Dec 2018 21:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/hadoop_block_placement_policy/</guid>
      <description>大多数的叫法都是副本放置策略，实质上是HDFS对所有数据的位置放置策略，并非只是针对数据的副本。因此Hadoop的源码里有block replicator(configuration)、 BlockPlacementPolicy(具体逻辑源码)两种叫法。
主要用途：上传文件时决定文件在HDFS上存储的位置（具体到datanode上的具体存储介质，如具体到存储在哪块硬盘）；rebalance、datanode退出集群、副本数量更改等导致数据移动的操作中，数据移动的具体位置。
BlockPlacementPolicy BlockPlacementPolicy 作为虚基类提供了基本的接口，具体的子类重点实现下面 选择副本 、 验证副本放置是否满足要求 、 选择能够删除的副本 三个函数：
/** * 核心的副本放置策略实现，返回副本放置数量的存储位置 * **如果有效节点数量不够（少于副本数），返回尽可能多的节点，而非失败** * * @param srcPath 上传文件的路径 * @param numOfReplicas 除下面chosen参数里已经选择的datanode，还需要的副本数量 * @param writer 写数据的机器, null if not in the cluster. 一般用于放置第一个副本以降低网络通信 * @param chosen 已经选择的节点 * @param returnChosenNodes 返回结果里是否包含chosen的datanode * @param excludedNodes 不选的节点 * @param blocksize 块大小 * @return 排序好的选择结果 */ public abstract DatanodeStorageInfo[] chooseTarget(String srcPath, int numOfReplicas, Node writer, List&amp;lt;DatanodeStorageInfo&amp;gt; chosen, boolean returnChosenNodes, Set&amp;lt;Node&amp;gt; excludedNodes, long blocksize, BlockStoragePolicy storagePolicy); /** * 判断传入的放置方式是否符合要求 */ abstract public BlockPlacementStatus verifyBlockPlacement( DatanodeInfo[] locs, int numOfReplicas); /** * 当副本数量较多时，选择需要删除的节点 */ abstract public List&amp;lt;DatanodeStorageInfo&amp;gt; chooseReplicasToDelete( Collection&amp;lt;DatanodeStorageInfo&amp;gt; candidates, int expectedNumOfReplicas, List&amp;lt;StorageType&amp;gt; excessTypes, DatanodeDescriptor addedNode, DatanodeDescriptor delNodeHint); Hadoop 提供的 BlockPlacementPolicy 实现 Hadoop提供了BlockPlacementPolicyDefault、BlockPlacementPolicyWithNodeGroup、AvailableSpaceBlockPlacementPolicy三种实现（hadoop 2.</description>
    </item>
    
    <item>
      <title>arch linux下网易云音乐运行没反应，只能使用root用户运行</title>
      <link>https://extendswind.top/posts/technical/netease_music_can_not_open/</link>
      <pubDate>Tue, 20 Nov 2018 19:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/netease_music_can_not_open/</guid>
      <description>最近打开网易云音乐没有反应，只在htop命令下能看到运行的进程（manjaro+mate+awesome）。
命令行sudo可以正常运行
无用尝试  安装官网给的最新1.1.3的deepin与ubuntu16两个版本 网上提到的&amp;ndash;no-sandbox参数运行 kill已经运行的netease-cloud-music相关进程  解决方案 回退到更早的1.0.0版，估计新版没有在各个linux系统下测试。
http://s1.music.126.net/download/pc/netease-cloud-music_1.0.0-2_amd64_ubuntu16.04.deb
debian系就直接dpkg -i吧
arch系通过AUR安装稍麻烦:
 卸载原版本 yaourt -S netease-cloud-music 按y Edit PKGBUILD 将1.1.3的安装包地址替换为1.1.0的安装包地址，并且将对应hash值改为skip，具体如下  改之前：
source=( &amp;quot;http://packages.deepin.com/deepin/pool/main/n/netease-cloud-music/netease-cloud-music_${pkgver}-${_pkgrel}_amd64.deb&amp;quot; &amp;quot;http://music.163.com/html/web2/service.html&amp;quot; ) md5sums=(&#39;53c47c1bf6797b2a0e455bc59833ab2d&#39; &#39;SKIP&#39;)  改之后
source=( &amp;quot;http://s1.music.126.net/download/pc/netease-cloud-music_1.0.0-2_amd64_ubuntu16.04.deb&amp;quot; &amp;quot;http://music.163.com/html/web2/service.html&amp;quot; ) md5sums=(&#39;SKIP&#39; &#39;SKIP&#39;)  然后正常安装即可</description>
    </item>
    
    <item>
      <title>leetcode: Median of Two Sorted Arrays</title>
      <link>https://extendswind.top/posts/technical/leetcode4/</link>
      <pubDate>Tue, 13 Nov 2018 10:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/leetcode4/</guid>
      <description>题目  Median of Two Sorted Arrays There are two sorted arrays nums1 and nums2 of size m and n respectively. Find the median of the two sorted arrays. The overall run time complexity should be O(log (m+n)). You may assume nums1 and nums2 cannot be both empty. Example 1: nums1 = [1, 3] nums2 = [2] The median is 2.0 Example 2: nums1 = [1, 2] nums2 = [3, 4] The median is (2 + 3)/2 = 2.</description>
    </item>
    
    <item>
      <title>使用AwesomeWM作为Mate(Gnome相同) Desktop的窗口管理器</title>
      <link>https://extendswind.top/posts/technical/using_awesomewm_as_wm_of_mate_desktop/</link>
      <pubDate>Sat, 20 Oct 2018 20:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/using_awesomewm_as_wm_of_mate_desktop/</guid>
      <description> 20190118更新:
最近发现有在非gnome系的DE下运行deepin-wine的解决方案，没必要专门跑一个mate。
安装gnome-setttings-daemon，然后运行/usr/lib/gsd-xsettings。（不同系统会不一样）
具体记录在另一篇博客
AwesomeWM这种平铺的窗口管理器用得很爽，只是基于wine的qq最近又莫名其妙抽风，感觉还是切到deepin-wine上比较靠谱。而deepin-wine在awesome下运行qq会报错X Error of failed request: BadWindow (invalid Window parameter) Major opcode of failed request: 20 (X_GetProperty)，而在Gnome系下运行正常。看到Gnome和Mate能够运行awesomewm，就折腾了一下试试。
Awesome只是Gnome等桌面管理器的组件之一，gnome系的Mate可以修改默认的窗口管理器。
具体折腾  安装AwesomeWM、Mate桌面环境与dconf-editor（arch下使用pacman -S）。
 进入Mate桌面环境后，修改org.mate.session.required-components windowmanager的值为&amp;rsquo;awesome&amp;rsquo;，如果不需要桌面上的图标，可以将org.mate.session.required-components的值只留下windowmanager。
 上面的设置无法通过命令行打开awesome，需要添加awesome的图标。在/usr/share/applications目录下新建awesome.desktop，内容如下（网上直接粘的，估计有些可以不要，懒得试了）：
[Desktop Entry] Type=Application Name=awesome Exec=awesome NoDisplay=true # name of loadable control center module X-MATE-WMSettingsModule=awesome # name we put on the WM spec check window X-MATE-WMName=awesome # back compat only X-MateWMSettingsLibrary=awesome X-MATE-Bugzilla-Bugzilla=MATE X-MATE-Bugzilla-Product=awesome X-MATE-Bugzilla-Component=general X-MATE-Autostart-Phase=WindowManager X-MATE-Provides=windowmanager X-MATE-Autostart-Notify=true   </description>
    </item>
    
    <item>
      <title>《十三邀》--李诞、马东、许知远</title>
      <link>https://extendswind.top/posts/life/_13_reviewes/</link>
      <pubDate>Sun, 30 Sep 2018 22:40:48 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/life/_13_reviewes/</guid>
      <description>看了奇葩说后查了一下李诞，又因为一些博客里提到了这个采访才看了《十三邀》。一个在综艺节目中脑回路极大、思维敏捷、搞笑，而又在生活中保持佛系态度,让我想看看采访中表达的思想。
看了对马东和李诞两个人的采访，五十多分钟的访谈看完了似乎没什么感觉，又印象有很多带动点思考的东西。
看一些评论有点意思，从一段对话里带着个人色彩解读，展示一些看不到的东西，虽然某些只以一个节目批判许知远人品和采访能力的论述略显浮躁。
评价一个人没什么意思，特别是以并不能展示全貌的公众视角，只谈看视频后的各种对自己的联想。
许知远似乎一直想表现出心底的与众不同，或者可能是在故意把自己的观点展示得更为偏激以试探对方的反应。很多地方表现出对当前社会状态的不满，期待对方有相同的感受，而感觉上马东和李诞都表示出某些理解，而现在又不属于同样的感觉。
马东作为一个老练的主持人表现得很成熟，表现出这个世界的悲凉，但又保持一个积极的态度，像是以一个太极的感觉回应许知远对时代的不满。
和李诞的访谈中，他们看起来是在以不同的方式做自己的坚持。一个处处展示自己知识分子的身份和追求，表现出愤青的批判；一个以佛系的心态面对生活，放低姿态以“浅薄”自嘲。
对当前的生活状态，显然谈不上不太满意，无论是能力还是心态上都还距离自己想要的高度甚远。过去的一段时间，想给自己贴上成熟的标签，但又总感觉少了点青春，某些严肃也显得和自己略不协调。在《天才在左，疯子在右》中某个善于模仿他人的“患者”提到，人一生的最理想状态或许是历经沧桑后老年人的那种平和。也经常想象自己在心态上的终极追求，年老时最想要达到的心态，或许，成熟之中，还需要李诞那样的一份佛系和“浅薄”。
记下的一点东西 李诞 佛系。
通过笑话说实话。
“人是社会动物，人就是为了别人活的，你充分的自得，活在自己的精神世界里面，你就死了”。
“好吧，我就是想活在浅薄里，我就是想活得流于表面。”
马东 每个时代都追求精致，但又难以找到精致。
开始《奇葩说》是因为有很多吸引他的未知的东西，技术、平台等。
人生的底色是凄凉，不像积极主义者，凄凉是指无法改变的东西。
“被误会是表达者的宿命”。</description>
    </item>
    
    <item>
      <title>git 代码回滚与爬坑 -- reset and revert</title>
      <link>https://extendswind.top/posts/technical/git_code_roll_back_revert_and_reset/</link>
      <pubDate>Tue, 11 Sep 2018 10:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/git_code_roll_back_revert_and_reset/</guid>
      <description>reset 某些特殊的情况下，需要回退到先前的某一次提交。
git log 查找想要回退的commit的id后运行：
git reset --hard 2c1e288
回退后git log只会显示回退版本之前的提交。如果需要返回最新的提交，使用git reflog查看对应的id。
git reset只适合本地的回退和查看先前代码。如果远程仓库已有最新的提交，git会认为远程仓库的代码较新，需要先同步远程代码再进行修改，此情况下建议使用revert。
git reset &amp;ndash;soft &amp;ndash;mixed &amp;ndash;hard 以HEAD～为例（HEAD前的一次提交）
git reset --soft HEAD~ 会回到前一次提交的commit执行之前的状态 git reset --mixed HEAD~ 会回到前一次提交的add执行之前的状态 git reset --hard HEAD~ 会回到前一次提交的add执行之前的状态，并且将目录里的所有文件调整为前一次的提交状态
通常回退时需要将文件也回退需要加 --hard 标签。
git的文件组织 git将所有的文件以hash码命名放在仓库中存储。
HEAD指针，一般可以理解为当前commit状态的一个快照（指向仓库中当前commit的所有的文件）。每次commit或者merge等会创建新的commit节点时，会让HEAD指向新的位置。
reset会改变HEAD指针的位置与HEAD对应的分支指针的位置，checkout只会改变HEAD指针指向的分支。
revert git revert &amp;lt;commit-id&amp;gt; 相当于取消一次commit ，会让结果和没有这一次提交一样，并非像reset那样直接回到某一次commit的代码。
使用revert不会破坏历史记录，只是提交一个新的修改使修改后代码和以前一致。
实质上相当于用前的代码merge 后的代码，因此如果后面对代码文件做了修改需要解决冲突。
revert一个merge commit 注意revert用在merge的commit上的情况有坑
git revert &amp;lt;commit-id&amp;gt; -m 1 需要添加-m参数，指定是merge前的第几个分支（git log上的merge后）。
revert的主要麻烦：如果存在分支合并的情况，如下，从m1 revert到a2时会添加一个新的提交m2，当m2与b2 merge时会显示已经merge过。
a1 -&amp;gt; a2 -&amp;gt; m1 -&amp;gt; m2 b1 -&amp;gt; b2 /</description>
    </item>
    
    <item>
      <title>SpatialHadoop的编译与运行</title>
      <link>https://extendswind.top/posts/technical/spatialhadoop_compile_and_run/</link>
      <pubDate>Wed, 05 Sep 2018 10:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/spatialhadoop_compile_and_run/</guid>
      <description>SpatialHadoop相对HadoopGIS等库，在MapReduce时代的空间数据处理开源库算处理较好。SpatialHadoop在效率上相对一些新的基于Spark空间数据处理开源库明显偏低，加上本身的功能实现得差不多，最近提交的更新越来越少，感觉发展趋势不太好，主要用于学习相关的索引技术。
编译与运行 主页上有已经编译好的包，可以直接解压到Hadoop目录下运行，但官方的版本解压有错误，因此下载github上源码编译。
需要的环境：
 jdk8 Hadoop 2.7.7 maven  源码编译 源码地址 https://github.com/aseldawy/spatialhadoop2，直接下载或者git clone到本地。
需要安装maven用于代码编译。
编译前将pom.xml文件中hadoop相关的版本改为需要的版本。
mvn compile 编译源码 mvn assembly:assembly 代码打包，会在target目录下生成jar和一个包含jar与相关依赖的tar.gz包
在2f1aefd32860d0279f2fc479a8bafb68d07e3761版本（Mar 13,2018）编译时会由于缺少一个测试文件测试失败，可以选择跳过测试，或者注释掉测试的代码（src/test/java/edu/umn/cs/spatialHadoop/indexing/RStarTreeTest.java中的某个函数）。
运行 首先需要有一个Hadoop集群，能够提交yarn任务。
将target目录下生成的tar.gz包（spatialhadoop-2.4.3-SNAPSHOT-bin.tar.gz）拷贝到Hadoop目录下并解压即可。
cp target/spatialhadoop-2.4.3-SNAPSHOT-bin.tar.gz $HADOOP_HOME/ cd $HADOOP_HOME tar -zxvf spatialhadoop-2.4.3-SNAPSHOT-bin.tar.gz Hadoop目录下运行下面的测试代码，会向HDFS中写入一个随机生成的矩形文件。
sbin/shadoop generate test.rects size:1.gb shape:rect mbr:0,0,1000000,1000000 -overwrite
SpatialHadoop运行机制 shadoop 脚本 SpatialHadoop 通过脚本shadoop运行命令，脚本就只有几行代码
bin=`dirname &amp;#34;$0&amp;#34;` bin=`cd &amp;#34;$bin&amp;#34; &amp;gt; /dev/null; pwd` # Call Hadoop with the operations.Main as the main class . &amp;#34;$bin&amp;#34;/hadoop edu.umn.cs.spatialHadoop.operations.Main $@ 其实只是将spatialhadoop的jar包与相关依赖jar包放入Hadoop的包目录中，然后通过shadoop脚本调用Hadoop脚本调用包中的一个类，向YARN提交MapReduce任务。</description>
    </item>
    
    <item>
      <title>Hadoop YARN 调度器（scheduler） —— 资源调度策略</title>
      <link>https://extendswind.top/posts/technical/hadoop_yarn_resource_scheduler/</link>
      <pubDate>Tue, 04 Sep 2018 10:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/hadoop_yarn_resource_scheduler/</guid>
      <description>搜了一些博客，发现写得最清楚的还是《Hadoop权威指南》，以下内容主要来自《Hadoop The Definitive Guide》 4th Edition 2015.3。
Hadoop YARN Scheduler 三个调度器 YARN提供了CapacityScheduler, FairScheduler, FifoScheduler三个调度器，继承于AbstractYarnScheduler，Resource Manager通过调度器决定对提交application分配的资源大小。
CapacityScheduler首先将所有资源分配到hierarchical queue中，每个任务执行时指定对应的queue，使大任务不会占用整个集群的资源，通过对queue的资源管理提高整个集群的资源共享能力。通常会使小任务执行更快，大任务更慢。
Fair Scheduler 会在第一个任务运行时分配当前同级队列的所有资源，当有其它任务运行时，回收前面任务运行时的部分资源（一般为运行完成的Container）用于其它任务。
至于FIFO，源码里都没有描述，可能就是一般的先进先出了。
YARN默认使用CapacityScheduler，通过下面的属性配置：
&amp;lt;property&amp;gt; &amp;lt;name&amp;gt;yarn.resourcemanager.scheduler.class&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler&amp;lt;/value&amp;gt; &amp;lt;/property&amp;gt; YARN 动态资源分配 YARN 能够动态申请资源，如MapReduce中reduce的container会在map过程结束后申请。但Spark On YARN的机制为申请固定的executor，而不动态改变已申请的资源。
YARN上新运行的任务能够使用已运行任务回收的资源(如运行完Map task的container)，甚至还能够通过强行结束先前任务的container抢占资源。
Capacity Scheduler CapacityScheduler重点解决多个组织共享集群资源，并保证每个组织自己的资源使用量。当自己的资源不足时能够使用其它组织的空闲资源。
资源通过层级队列（hierarchical queues）的形式进行组织，配置在etc/hadoop/capacity-scheduler.xml.
&amp;lt;!-- 队列结构设置 --&amp;gt; &amp;lt;property&amp;gt; &amp;lt;name&amp;gt;yarn.scheduler.capacity.root.queues&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;a,b&amp;lt;/value&amp;gt; &amp;lt;description&amp;gt;The queues at the this level (root is the root queue). &amp;lt;/description&amp;gt; &amp;lt;/property&amp;gt; &amp;lt;property&amp;gt; &amp;lt;name&amp;gt;yarn.scheduler.capacity.root.a.queues&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;a1,a2&amp;lt;/value&amp;gt; &amp;lt;description&amp;gt;The queues at the this level (root is the root queue).</description>
    </item>
    
    <item>
      <title>使用Python3发布博客到支持mateweblog的平台（博客园等）</title>
      <link>https://extendswind.top/posts/technical/python3_publish_blog/</link>
      <pubDate>Tue, 04 Sep 2018 10:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/python3_publish_blog/</guid>
      <description>用个人域名搭建的博客在百度搜索上的SEO太差，百度一直只收录主页，懒得再为这些问题折腾，直接同步到博客园算了，考虑用Python。
貌似CSDN已经关闭了metawebblog接口，只在博客园上测试。
Python发博客的主要方案  通过xmlprc的metaweblog接口（首选） CSDN和博客园的api（定位不是用来发博客的，申请key和调接口略麻烦） 使用抓包的技术模拟浏览器登录发博客（没悬念更折腾）  代码 对于支持metaweblog的博客平台，只要提供用户名、密码和博客相关信息。
python2 需要将后面的xmlrpc.client改为xmlrpclib，并且import xmlrpclib
#!/bin/python3 import xmlrpc.client username = &amp;#39;&amp;#39; # TODO your username passwd = &amp;#39;&amp;#39; # TODO your passwd url = &amp;#39;http://www.cnblogs.com/fly2wind/services/metaweblog.aspx&amp;#39; title = &amp;#34;helloWorld&amp;#34; content = &amp;#34;&amp;lt;p&amp;gt; test &amp;lt;p&amp;gt;&amp;#34; tags = &amp;#34;tag1, tag2&amp;#34; blogProxy = xmlrpc.client.ServerProxy(url) # 获取最近博客列表 print(blogProxy.metaWeblog.getRecentPosts(&amp;#39;&amp;#39;, username, passwd, 1)) # 发布博客 blogProxy.metaWeblog.newPost(&amp;#39;&amp;#39;, username, passwd, dict(title=title, description=content, mt_keywords=tags), True) 参考 https://rpc.cnblogs.com/metaweblog/fly2wind#Post API文档
https://magicsword.wordpress.com/2012/01/17/tet34/
https://blog.csdn.net/shajunxing/article/details/79553472
https://github.com/RussellLuo/pymwa</description>
    </item>
    
    <item>
      <title>静态blog的免费托管部署、加域名与搜索优化（SEO）</title>
      <link>https://extendswind.top/posts/technical/hugo_blog_host_and_seo/</link>
      <pubDate>Tue, 04 Sep 2018 10:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/hugo_blog_host_and_seo/</guid>
      <description> 给博客加个域名准备长用，Hugo生成后一直放在github page上，为了让百度能搜到费了一堆事。
问题 如果只是在github page上弄个自己域名的网站，只需要在结果文件中添加一个CNAME文件，写入网站域名，然后在域名运营商提交解析。等待域名解析生效后即可通过域名访问。
然后为了让搜索引擎能够检索，通过baidu、bing、google的站长工具提交链接。
此时发生一个大bug，github因为某种原因限制了百度爬虫的进入，也就是百度上很少搜到github内网页的原因。
重点解决的问题为：github page上的内容无法被百度检索。
解决方案 相关解决github page被检索的方案较多，重点都是通过CDN缓存网站和将网站托管在其它地方两个方案。
CDN略麻烦，还需要其它的服务。 在各种折腾之后选择了托管在netlify上，然后在百度站长工具中提交网站。
还没完 Hugo的sitemap百度无法识别 Hugo默认可以使用多语言，当设置了中文和英文时，默认路径下的sitemap会指向两种语言的sitemap路径而非直接的网页，百度无法识别&amp;hellip;.
解决方案，只设置一种语言。
百度长时间只收录主页（收录链接数为1） 百度能看到一堆人碰到类似的问题。
有解决方案建议放在CSDN一类的普通博客上，并附上链接，百度时间长了会自动收录。（google就没这问题&amp;hellip;）
还有稳定更新，提高博客的质量。
然后静静的等待&amp;hellip;.
附：国内外的免费静态网站托管 国外代码托管系列
 netlify，最好最方便，没有之一，添加域名和github仓库的地址就能解决问题，github上的提交还会自动同步。 github page，网页放上去选择显示的分支即可，网速虽然没有飞起但在教育网下还行，主要问题在于上面提到的，百度搜索不到&amp;hellip; gitlab，同github，但使用了Docker技术提高了构建能力，能够上传源博客在服务端构建。只是折腾了一会，fork的项目构建网页一直失败，懒得再debug&amp;hellip; bitbucket，同github，一个大bug在于不能直接添加域名，域名解析过去无效，需要额外的服务（又是一堆配置）  国内代码托管
 码云，同github，但添加域名是收费功能。 coding，之前博客提到的最多，貌似最近加入了广告，进入网页前几秒会跳入广告页（略不能忍）。  </description>
    </item>
    
    <item>
      <title>Hadoop HDFS 远程调试（Docker环境下的Hadoop集群）</title>
      <link>https://extendswind.top/posts/technical/remote_debug_of_hadoop_in_docker/</link>
      <pubDate>Thu, 26 Jul 2018 21:30:00 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/remote_debug_of_hadoop_in_docker/</guid>
      <description>Hadoop 典型的调试方式是通过log4j输出日志，基于日志的形式查看运行信息。在源码阅读中，经常有不容易猜的变量，通过大量日志输出调试没有远程调试方便。
Java 远程调试 不想了解的可以直接跳到下面Hadoop
通过JPDA（Java Platform Debugger Architecture），调试时启动服务，通过socket端口与调试服务端通信。
下面只用最常用的服务端启动调试服务监听端口，本地IDE（idea）连接服务端。
具体操作 1、启动被调试程序时添加参数：  jdk9: -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=*:8000
jdk5-8: -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8000
jdk4: -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8000
jdk3 及以前: -Xnoagent -Djava.compiler=NONE -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8000
 此处有坑，网上大部分没有提到jdk版本不同导致的区别，很多博客使用jdk4的写法，可能导致问题（idea配置远程调试时有上面的选项）。
另外一个小坑, 下面第一个命令正常执行，第二个命令会忽略调试选项：
 java -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8000 test java test -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8000  主要参数。suspend=y时，程序启动会先挂起，IDE连接后才会运行；suspend=n时，程序启动会直接运行。address后面为端口号，不与其它端口重合即可。
2、启动Idea连接调试 使用idea打开调试项目的源码工程
Run -&amp;gt; Edit Configurations , 点“加号” -&amp;gt; remote，然后填上被调试程序所在主机的ip以及上面的address对应端口号，并选择源码所在的module。
添加后debug运行，剩下的和本地调试相同。
Hadoop 远程调试 思路和上面的操作一致。下面以调试HDFS中的namenode为例。
具体操作 1、修改Hadoop启动参数为debug模式 如果需要调试namenode服务，在etc/hadoop/hadoop-env.sh文件后添加：
export HDFS_NAMENODE_OPTS=&amp;quot;-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8000&amp;quot;
HDFS启动的jvm主要为namenode和datanode，jvm启动的参数设置在etc/hadoop/hadoop-env.sh中。其中namenode启动参数环境变量为 HDFS_NAMENODE_OPTS，datanode为 HDFS_DATANODE_OPTS（针对Hadoop3，hadoop2的设置为HADOOP_NAMENODE_OPTS HADOOP_NAMENODE_OPTS）。YARN等服务对应的环境变量需要另查。
2、启动服务 sbin/start-dfs.sh 或者 bin/hdfs --daemon start namenode仅启动namenode</description>
    </item>
    
    <item>
      <title>使用u盘安装linux(manjaro)时Grub报错</title>
      <link>https://extendswind.top/posts/technical/manjaro_install_problem_grub/</link>
      <pubDate>Tue, 17 Jul 2018 20:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/manjaro_install_problem_grub/</guid>
      <description>错误  error: invalid arch-independent ELF magic. Entering rescue mode&amp;hellip; grub rescue&amp;gt;
 使用Rufu ISO模式烧录的U盘，lagency 模式能够启动，但点安装后出上面错误；UEFI模式直接出上面错误。
解决方案 不多说，百度背锅，google答案的前几个就是正解。
U盘烧录问题，使用rufu烧录U盘时，最好使用DD模式而非ISO模式。（去年安装manjaro-xfce4时用ISO模式没出过）
https://forum.manjaro.org/t/grub-error-computer-with-no-os-installed-invalid-arch-independent-elf-magic/21805
解决方案：使用Rufu烧录U盘，点开始后会有选择DD模式或者ISO模式，此时选DD模式，然后UEFI启动即可。
论坛上还推荐使用etcher</description>
    </item>
    
    <item>
      <title>开启不折腾模式</title>
      <link>https://extendswind.top/posts/technical/from_geeker_to_no_self_inflicted/</link>
      <pubDate>Tue, 17 Jul 2018 20:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/from_geeker_to_no_self_inflicted/</guid>
      <description>用了很长一段时间的linux，和很多人对linux相比windows的优点评价相同，linux是非常自由的操作系统。从内核到桌面环境到各个应用都可以自行定制，能够完全按照自己的喜好修改，实在没有的功能甚至能够自己造轮子。
也因此对于我这样的强迫症患者，在各个组件上都想追求一个最舒适的解决方案。这样一个系统确实用得舒服，但也总有用得不舒服的地方需要持续改善，不断调整各个组件以及造一些脚本级的轮子。
最近连续几周效率严重偏低，也突然发现自己在这些看似意义不大的地方耗费的时间太多。一个emacs各种折腾最后只是写写简单的c++、Python和org；awesomeWM嵌入Mate其实相比传统的多workspace方式也没特别大的区别；软件尽可能找到开源替代与商业版本隔离。
或许太多时候以geek自居追求某种“无强迫”环境，而忘记要事优先。
提醒一下自己刚开始读研的目标，在一堆感兴趣的hello world基础之上有所深入。
感兴趣的技术太多，总要有所舍弃。
linux是用来折腾的，更是用来解决问题的。</description>
    </item>
    
    <item>
      <title>设计模式 之 原型模式</title>
      <link>https://extendswind.top/posts/technical/design_patterns_prototype/</link>
      <pubDate>Tue, 03 Jul 2018 21:25:25 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/design_patterns_prototype/</guid>
      <description>吐槽 感觉这是至今最值得吐槽的设计模式之一，由于原型模式在本质上与工厂模式极为类似，并且简单，但相关的书和博客很少提到要点。某些书上和博客还直接在类里加个clone方法就告诉我这是原型模式，不说清楚为什么要划分原型类和具体类&amp;hellip;.
还有某些书上把原型模式划分为通用实现和java、c#一类的特定语言实现，不就是稍微改改clone函数的具体实现么，一点简单的语法而已&amp;hellip;.
有些地方提到原型模式与工厂模式类似，而极少有位置提到后面的客户端的实现问题&amp;hellip;.
感觉原型模式没什么意思，实质上就是把工厂模式中new的过程改为clone，具体的类对应于完成初始化的多个对象。
原型模式（Prototype Pattern） 首先画重点，原型模式是一种 创建对象 的模式。通过复制已经初始化好的对象以避免对对象进行某些复杂和耗时的初始化过程。可能存在多个被复制的对象，创建自不同的类或同一个类的不同初始化过程，用户需要动态决定复制哪一个对象。
主要实现思想：
 对象的复制只需要在每个类中实现一个clone函数即可 使用工厂模式相关思想获取具体的clone对象  java实现的clone操作 下面的实现基于java，如c++一类的语言对于每个对象的复制需要自行处理。
java的所有类都继承于Object，Object类中定义了native实现的clone函数，但需要实现Cloneable接口才能调用。通过clone函数能够直接复制内存中的对象而不用调用构造函数。
注意，java Object的clone函数为 浅拷贝，只会复制类成员对象地址而不创建新的对象。需要根据实际情况判读是否做相应的深拷贝修改。 吐槽：很多博客和书上的示例实质上就下面这一段，然后加个实例里n个成员变量和函数凑出十几到几十行，实现个Cloneable接口加个clone函数就算完了&amp;hellip;.
class Prototype implements Cloneable{ int attr; public Prototype clone(){ Prototype prototype = null; try { prototype = (Prototype)super.clone(); } catch (CloneNotSupportedException e) { e.printStackTrace(); } return prototype; } } 一个不使用java特性的简单实现 class Prototype{ int attr; public Prototype clone(){ Prototype clone = new Prototype(); clone.attr = this.attr; return clone; } } 同上，注意深拷贝和浅拷贝问题。</description>
    </item>
    
    <item>
      <title>设计模式 之 单例模式</title>
      <link>https://extendswind.top/posts/technical/design_patterns_singleton/</link>
      <pubDate>Mon, 02 Jul 2018 11:25:25 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/design_patterns_singleton/</guid>
      <description>singleton pattern
主要目标：对象只创建一次，每次都获得先前第一次创建的对象而不创建新的对象。
实现思想：使用静态方法getInstance得到对象，为了保证对象只能通过getInstance创建，使构造函数私有。
主要麻烦在于：
 多线程环境下getInstance方法的调用可能产生多个对象 使用synchronized关键字可能降低高并发效率  单例模式有很多种，大多用于解决多线程环境下的效率问题，高并发场景可以具体搜索相关方案，一般情况下思想比较简单感觉不必深究。
（后面懒得用实际例子命名了，Log4j中获取的logger对象就使用了单例模式）
/** * 简单实现 * * 存在的问题： * * 当创建过程需要时间时，连续调用getInstance方法会导致创建多个对象，特别是涉及多线程时容易出问题。 */ class Singleton_problem { private static Singleton_problem m_singletonProblem = null; private Singleton_problem(){ // ...  } public static Singleton_problem getInstance(){ if (m_singletonProblem == null) m_singletonProblem = new Singleton_problem(); return m_singletonProblem; } } /** * 解决方案一： eager initialization * * 缺点在于没有lazy loading机制 */ class Singleton_eager{ private static final Singleton_eager m_singleton = new Singleton_eager(); private Singleton_eager(){ // .</description>
    </item>
    
    <item>
      <title>linux桌面发行版简介</title>
      <link>https://extendswind.top/posts/technical/linux_desktop_distribution/</link>
      <pubDate>Fri, 29 Jun 2018 20:59:49 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/linux_desktop_distribution/</guid>
      <description>linux系统 桌面操作系统：windows，MacOS和各linux发行版。
2017年数据，windows份额超过90%，MacOS约6%，Linux份额最高的记录在2016年7月创下，是2.33%。
貌似用linux和MacOS的大多是程序员了。MacOS和linux系统正常使用（看书、上网、看电影等）已经比较成熟，没有太大的体验差异。
linux系统的主要缺点：
 某些常用软件在linux上没有或运行有问题（qq、迅雷、office等，只有deepin通过虚拟windows系统解决得稍好） 完美折腾需要掌握大量相关知识，不折腾难以体现其优点 某些设置复杂（较好的发行版已有极大的改善，某些操作需要使用命令）  linux作为桌面系统主要优点（作为服务器系统广泛使用不谈）：
 软件管理容易 可定制性超强 免费（看版权意识）  对于开发人员，大部分的软件一键安装还解决依赖问题，想要的操作大部分可以通过修改配置和安装软件实现。在运行某些开发软件会明显感觉更快，绝大部分配置通过文本文件容易修改。
linux发行版 一般的linux发行版包括：Linux内核，一些GNU程序库和工具，命令行shell，图形界面的X Window系统和相应的桌面环境，以及一系列其他的软件包（浏览器、阅读器、文本编辑器等）。由各种组织和个人维护。
主要用过的几个桌面发行版：  也许桌面用户最多的Ubuntu 不折腾的Arch系Manjaro （当前主力） 和Manjaro在distrowatch上争第一的Ubuntu进化版Mint 号称最美linux的Elementary 超稳定适合服务器的版本Centos （只在服务器上用） 最强国产化linux的Deepin和一般国产化的优麒麟  下面叙述中不包含在内的主要道听途说
主流的发行版 debian系：Debian -&amp;gt; Ubuntu -&amp;gt; Mint | Elementary | Deepin | 优麒麟 fedora : Fedora -&amp;gt; RHEL -&amp;gt; Centos | Oracle linux SUSE : SUSE -&amp;gt; SLES -&amp;gt; openSUSE (没有用过，大多对其评价较为中立，暂不讨论) arch : Arch -&amp;gt; Manjaro gantoo
其中箭头后的系统基于前面的系统发展，但并不影响前面系统的优势。如Ubuntu基于Debian系统成为较好的桌面系统，但Debian由于其轻量级和可定制仍有广泛使用。</description>
    </item>
    
    <item>
      <title>设计模式 之 静态代理模式和装饰者模式</title>
      <link>https://extendswind.top/posts/technical/design_patterns_static_proxy_and_decoration/</link>
      <pubDate>Wed, 20 Jun 2018 17:25:25 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/design_patterns_static_proxy_and_decoration/</guid>
      <description>这两种模式的相似度极高，作用也类似，都是对已有的类进行包装，以添加新的控制（代理模式）和功能（装饰者模式），其实这两点也没有严格区分。
两种设计模式的重点在于，已有的类（被代理、被装饰）与新类（代理类、装饰类）都实现同一接口，通过接口调用新类会和调用已有的类相同。
设计模式中常说使用“组合”优先于“继承”。对于想要改变一个写好的类中的某些功能，一般情况下使用继承的灵活性不如组合。继承的某些缺点：单继承（多继承也面临一些问题）、破坏封装（子类可能改变某些细节），父类的改变对子类可能有影响。“组合”的方式将需要被修改或加强的类作为新类的类成员，可以通过添加多个类成员以得到组合多种功能的效果。
静态代理模式 （static proxy） 静态代理的思想：将被代理类作为代理类的成员，通过代理类调用被代理类的函数，并添加新的控制。包装类与被包装类实现同一接口，使得使用时的代码一致。
应用：已经有一个日志记录器LoggerSubject，需要对writeLog()函数的前后进行某些操作（如初始化、异常处理等），使用Proxy类间接调用LoggerSubject.writeLog()实现新控制操作的添加。
实现如下
interface Logger { void writeLog(); } // 被代理类 class LoggerSubject implements Logger{ @Override public void writeLog(){ System.out.println(&amp;#34;writeLog by LoggerSubject&amp;#34;); } } // 代理类 class Proxy implements Logger{ Logger logger; // 与装饰者模式的主要区别位置  // 代理模式一般要求和原来的类行为一致，因此构造函数不传入对象  Proxy(){ this.logger = new LoggerSubject(); } @Override public void writeLog(){ System.out.println(&amp;#34;logger write before&amp;#34;); logger.writeLog(); System.out.println(&amp;#34;logger write after&amp;#34;); } } public class StaticProxy { private static void write(Logger logger){ logger.</description>
    </item>
    
    <item>
      <title>设计模式 之 工厂模式</title>
      <link>https://extendswind.top/posts/technical/design_patterns_factory/</link>
      <pubDate>Fri, 15 Jun 2018 17:25:25 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/technical/design_patterns_factory/</guid>
      <description>TODO 某些思想感觉没写清楚和有重复
几种工厂模式(Factory Pattern)简介 工厂模式主要分为：
 简单工厂模式（Simple Factory Pattern） 工厂方法模式（Factory Method Pattern 经常简称为工厂模式） 抽象工厂模式（Abstract Factory Pattern）  主要思想：将类的创建逻辑转移到工厂类中，工厂类直接得到初始化后的产品类，使产品类的初始化逻辑清晰、一致，容易添加新的产品。
目标：
 将产品的创建逻辑(如读取本地文件、连接数据库）放入工厂类，简化使用逻辑。 隐藏具体创建的对象，提高代码的通用性 （网上博客很多地方没提这点，只有结合java反射机制才行）  需求示例 简单工厂模式 和 工厂方法模式  实现多个日志记录器logger(文件logger，数据库logger等) 通过配置文件确定使用的具体logger类 添加新的logger类不修改源码（添加新的java包并修改配置文件）  抽象工厂模式 抽象工厂模式应用场景略有不同。
存在多种不同的主题，每个主题都有不同的Button和Text的实现逻辑，因此每个主题都有Button和Text控件的派生类，导致类的初始化较多。
容易添加新的主题
不应用工厂模式的一般实现 （FactoryProblem.java）  logger 基类实现通用的日志记录功能，子类实现各自的特有功能 使用时根据配置文件中的类型，new相应的子类  类的实现：
abstract class Logger { public void writeLog(){ System.out.println(&amp;#34;writeLog by Logger&amp;#34;); } // 可添加公共实现 } class FileLogger extends Logger { @Override public void writeLog(){ System.out.println(&amp;#34;writeLog by the FileLogger&amp;#34;); } } class DataBaseLogger extends Logger { @Override public void writeLog(){ System.</description>
    </item>
    
    <item>
      <title>第一篇博客</title>
      <link>https://extendswind.top/posts/life/blog_first/</link>
      <pubDate>Mon, 04 Jun 2018 22:40:48 +0800</pubDate>
      
      <guid>https://extendswind.top/posts/life/blog_first/</guid>
      <description>终于初步搞定了这个博客，Hugo虽然自称最快，但要想找个合适的主题外加适应中文真不是一般的折腾，各种css调了半天还没达到想要的效果。只是作为一个折腾的helloworld程序员，即便有aur一键安装，也难忍搞个博客还要来一波nodejs或ruby。
改成中文各种看起来不舒服，还没搞清楚具体怎么翻译。域名申请还是等后面有点内容的时候再说吧。
搞个博客能干啥，最近发现自己一直违背了高效工作必备的“要事优先”原则，博客园、简书、豆瓣等不折腾平台还是够用了。不过还是有点折腾博客的理由：不想多个平台换；感觉博客这东西应该用git一类的工具管理；吐槽学术界大部分方向的封闭；一键上传；说不定写写小说好用；看到很多人用；反正就是折腾了。
作为一个还在学术界又不确定以后会不会在学术界的半个researcher，准备先走走技术流，有个博客记录总是好的。
聊聊技术，谈谈学术，写写人生。</description>
    </item>
    
  </channel>
</rss>